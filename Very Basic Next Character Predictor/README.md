Replicate the [notebook](https://nipunbatra.github.io/ml-teaching/notebooks/names.html) on the next character prediction and use it for generation of text. Use one of the datasets specified below for training. Refer to Andrej Karpathyâ€™s blog post on [Effectiveness of RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). Visualise the embeddings using t-SNE if using more than 2 dimensions or using a scatter plot if using 2 dimensions. Write a streamlit application which asks users for an input text and it then predicts next k characters [5 marks]

Datasets (first few based on Effectiveness of RNN blog post from Karpathy et al.)
a. Paul Graham essays
b. Wikipedia (English)
c. Shakespeare
d. [Maths texbook](https://github.com/stacks/stacks-project)
e. Something comparable in spirit but of your choice
